\chapter{Tre algoritmi per ordinare con informazione parziale}

% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ %
\section{Ordinamento con informazione parziale} Sia \(V=\left\{v_1,\dots,v_n\right\}\) un insieme dotato di un ordine totale \(\le\) fissato ma ignoto. Supponiamo di conoscere un sottoinsieme delle relazioni del tipo \(v_i\le v_j\). Il problema dell'ordinamento con informazione parziale consiste nel determinare l'ordine totale per mezzo di interrogazioni del tipo ``\(\text{\emph{è vero che}}\;v_i\le v_j\;\text{?}\,\)''. 
\begin{theorem}
	[Kahn, Kim] Sia \(P\) un insieme parzialmente ordinato di cardinalità \(n\). Allora vale
	\[nH\left(\overline{P}\right)\le\min\left\{\log{e(P)}+\log{e\cdot n},\; c\log{e(P)}\right\}\]
	dove \(c=1+7\log{e}\approx 11.1\). 
\end{theorem}
\begin{theorem}
	[Cardinal, Fiorini, Joret, Jungers, Munro] Sia \(P\) un insieme parzialmente ordinato di cardinalità \(n\). Allora vale
	\[nH\left(\overline{P}\right)\le 2\log{e(P)}.\]
\end{theorem}
\begin{proof}
	La dimostrazione procede per induzione su \(n\), e, per \(n\) fissato, sul numero di elementi inconfrontabili di \(P\). Essendo la tesi banalmente vera per \(n=1\) supporremo che sia \(n\ge 2\). Sia \(x\in \mathbb{R}_{+}^{V}\) un vettore che realizzi il minimo dell'entropia. Sia inoltre \(\left\{\left(y_{v^-},y_{v^+}\right)\right\}_{v\in V}\) la corrispondente collezione di intervalli. Sia infine \(a\in V\) tale che \(y_{a^+}\) sia massimo. Se \(a\) fosse confrontabile con tutti gli elementi di \(V\) avremmo per ipotesi induttiva che
	\[nH\left(\overline{P}\right)=(n-1)H\left(\overline{P-a}\right)\le 2\log{e(P-a)=2\log{e(P)}}.\]
	Sia allora \(b\) non confrontabile con \(a\) e tale inoltre che \(y_{b^+}\) sia massimo. Per come abbiamo scelto \(a\) deve per forza essere \(y_{b^+}\le y_{a^+}\). In realtà vale l'uguaglianza. Supponiamo per assurdo che \(y_{b^+}<y_{a^+}\), ed estendiamo a destra l'intervallo corrispondente a \(b\) di \(y_{a^+}-y_{b^+}\). Questa nuova collezione di intervalli è ancora consistente con \(P\), ma il punto \(x'\in \mathbb{R}_{+}^{V}\) da essa definito realizzerebbe un valore dell'entropia più piccolo del minimo. Abbiamo infatti
	\[-\frac{1}{n}\sum_{v\in V}{\log{x'_{v}}}=-\frac{1}{n}\sum_{v\in V}{\log{x_{v}}}+\frac{1}{n}\left(\log{x_b}-\log{x'_{b}}\right)<-\frac{1}{n}\sum_{v\in V}{\log{x_v}},\]
	contro l'ipotesi che \(x\) realizzi il minimo dell'entropia. A meno di scambiare \(a\) e \(b\) possiamo ora supporre che \(x_a\ge x_b\). Il nostro obiettivo ora è definire due nuove famiglie di intervalli
	\[\left\{\left(y_{v^-}^1, y_{v^+}^1\right)\right\}_{v\in V}\qquad\mbox{ e }\qquad\left\{\left(y_{v^-}^2, y_{v^+}^2\right)\right\}_{v\in V}\]
	tali che gli insiemi parzialmente ordinati \(P_1\) e \(P_2\) ad esse associati estendano \(P\), e tali inoltre che le quantità \(e(P_1)\) ed \(e(P_2)\) varino in modo controllato. Per fare questo poniamo
	\[\lambda=\frac{x_b}{x_a},\]
	compreso fra \(0\) e \(1\) per come abbiamo scelto \(a\) e \(b\). Poniamo inoltre
	\[\alpha_1= 
	\begin{cases}
		\frac{1}{1-\lambda} & \mbox{se } \lambda\le\frac{1}{2} \\
		2 & \mbox{altrimenti} 
	\end{cases}
	\qquad\mbox{ e }\qquad \beta_1= 
	\begin{cases}
		1 & \mbox{se } \lambda\le\frac{1}{2} \\
		2\lambda & \mbox{altrimenti} 
	\end{cases}
	\]
	e infine
	\[\alpha_2=\frac{2}{\lambda}\qquad\mbox{ e }\qquad\beta_2=2.\]
	Allora la famiglia di intervalli \(\left\{\left(y_{v^-}^1, y_{v^+}^1\right)\right\}_{v\in V}\) coincide con \(\left\{\left(y_{v^-}, y_{v^+}\right)\right\}_{v\in V}\) tranne per 
	\begin{align}
		y_{a^+}^1 &= y_{a^-} + \frac{x_a}{\alpha_1} \nonumber \\
		y_{b^-}^1 &= y_{b^+} - \frac{x_b}{\beta_1}, \nonumber 
	\end{align}
	e analogamente \(\left\{\left(y_{v^-}^2, y_{v^+}^2\right)\right\}_{v\in V}\) coincide con \(\left\{\left(y_{v^-}, y_{v^+}\right)\right\}_{v\in V}\) eccetto per 
	\begin{align}
		y_{a^-}^2 &= y_{a^+} - \frac{x_a}{\alpha_2} \nonumber \\
		y_{b^+}^2 &= y_{b^-} + \frac{x_b}{\beta_2}. \nonumber 
	\end{align}
	Siano rispettivamente \(P_1\) e \(P_2\) gli insiemi parzialmente ordinati definiti dalla prima e dalla seconda famiglia di intervalli. Allora esiste un indice \(i\in\left\{1,2\right\}\) tale che 
	\begin{equation}
		\label{appendixlemma} \frac{e(P_i)}{e(P)}\le\frac{1}{\sqrt{\alpha_i\beta_i}}. 
	\end{equation}
	Questo fatto verrà dimostrato in appendice. Assumendo che esista un tale \(i\) sia \(x'\in\mathbb{R}_{+}^V\) il vettore definito dalla corrispondente famiglia di intervalli. Abbiamo allora che
	\[H(P_i)\le-\frac{1}{n}\sum_{v\in V}{\log{x'_v}=-\frac{1}{n}\sum_{v\in V}{\log{x_v}}+\frac{1}{n}\log{\alpha_i}+\frac{1}{n}\log{\beta_i}},\]
	dunque
	\[nH(P_i)\le nH(P)+\log{\alpha_i\beta_i}.\]
	Possiamo ora concludere. Per il teorema \ref{lovasztheorem} e per la disuguaglianza appena dimostrata possiamo scrivere 
	\begin{align}
		nH(\overline{P}) &= n\log{n}-nH(P) \nonumber \\
		&\le n\log{n}-nH(P_i)+\log{\alpha_i\beta_i} \nonumber \\
		&= nH(\overline{P_i})+\log{\alpha_i\beta_i}, \nonumber 
	\end{align}
	mentre per ipotesi induttiva e per la disuguaglianza \ref{appendixlemma} abbiamo 
	\begin{align}
		nH(\overline{P_i})+\log{\alpha_i\beta_i} &\le 2\log{e(P_i)}+\log{\alpha_i\beta_i} \nonumber \\
		&\le 2\log{\frac{e(P)}{\sqrt{\alpha_i\beta_i}}}+\log{\alpha_i\beta_i} \nonumber \\
		&\le 2\log{e(P)} \nonumber 
	\end{align}
	cioè la tesi.\qed 
\end{proof}

% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ %
\section{Insertion sort} 
\begin{algorithm}
  \caption{``Insertion sort''} \label{insertion}
	\begin{algorithmic}
	  \STATE \, \COMMENT Preparazione
		\STATE trova una catena \(C\) di lunghezza massima in \(P\)
		\STATE \, \COMMENT Ordinamento
		\WHILE{\(P-C\neq\varnothing\)} 
		  \STATE togli un elemento da \(P-C\) e inseriscilo in \(C\) con una ricerca binaria 
		\ENDWHILE
		\RETURN \(C\) 
	\end{algorithmic}
\end{algorithm}
\begin{lemma}
	Sia \(P\) un insieme parzialmente ordinato di cardinalità \(n\) e sia \(C\) una catena di lunghezza massima in \(P\). Vale allora \(\left|C\right|\ge n\cdot2^{-H(\overline{P})}\). 
\end{lemma}
\begin{proof}
  TODO\qed
\end{proof}
\begin{theorem}
  L'algoritmo \ref{insertion} compie \(O(\log{n}\cdot\log{e(P)})\) confronti.
\end{theorem}
\begin{proof}
  TODO\qed
\end{proof}

% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ %
\section{Merge sort naive}
\begin{algorithm}
  \caption{``Merge sort naive''} \label{naivemerge}
	\begin{algorithmic}
	  \STATE \, \COMMENT Preparazione
		\STATE trova una decomposizione golosa di \(P\) in catene \(C_1,\dots,C_k\)
		\STATE \(\mathcal{C}\leftarrow\left\{C_1,\dots,C_k\right\}\)
		\STATE \, \COMMENT Ordinamento
		\WHILE{\(|\mathcal{C}|>1\)} 
		  \STATE seleziona da \(\mathcal{C}\) due catene di lunghezza minima \(C\) e \(C'\)
		  \STATE fondi \(C\) e \(C'\) in tempo lineare, ottenendo \(C''\)
		  \STATE cancella \(C\) e \(C'\) da \(\mathcal{C}\), aggiungi \(C''\)
		\ENDWHILE
		\RETURN l'unica catena di \(\mathcal{C}\)
	\end{algorithmic}
\end{algorithm}
\begin{lemma}
  TODO
\end{lemma}
\begin{proof}
  TODO\qed
\end{proof}

% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ %
\section{Merge con informazione parziale} 
\begin{lemma}
	\label{structurelemma} Sia \(P\) un insieme parzialmente ordinato ricoperto da due catene disgiunte \(A\) e \(B\) e sia \(G=\overline{G}(P)\) il grafo ad esso associato. Allora 
	\begin{itemize}
		\item \(G\) è bipartito 
		\item \(G\) è biconvesso 
		\item \(G\) Siano \(u\) e \(v\) vertici appartenenti alla stessa catena, che supporremo senza perdita di generalità essere \(A\), tali che \(u\le_{P} v\). Siano \([c_u,d_u]\) e \([c_v,d_v]\) gli intervalli dei vertici \(B\) adiacenti rispettivamente a \(u\) e \(v\). Allora \(c_u\le_{P} c_v\) e \(d_u\le_{P} d_v\), e in particolare se \(u\le_{P}w\le_{P}v\) i vertici adiacenti a \(w\) sono un intervallo contenuto in \([c_u,d_v]\). 
	\end{itemize}
\end{lemma}
\begin{proof}
	TODO\qed 
\end{proof}
\begin{definition}
	Diremo che un arco \(uv\) è \emph{stretto} rispetto ad \(x\in\text{STAB}(G)\) se vale \(x_u+x_v=1\). Denoteremo con \(G(x)\) il grafo i cui vertici siano gli stessi di \(G\) e i cui archi siano stretti rispetto ad \(x\). 
\end{definition}
\begin{definition}
	Siano \(uv\) e \(u'v'\) archi di \(G\) tali che \(u,u'\in A\) e \(v,v'\in B\). Diremo che \emph{si incrociano} se \(u<_{P}u'\) e \(v'<_{P}v\) oppure se \(u'<_{P}u\) e \(v<_{P}v'\). 
\end{definition}
\begin{lemma}
	\label{crossinglemma} Sia \(P\) un insieme parzialmente ordinato ricoperto da due catene disgiunte \(A\) e \(B\) e sia \(G=\overline{G}(P)\) il grafo ad esso associato. Sia \(x\) un punto di \(\text{STAB}(G)\) e siano \(uv\) e \(u'v'\) archi stretti rispetto ad \(x\) tali inoltre che \(u,u'\in A\) e \(v,v'\in B\). Se \(uv\) e \(u'v'\) si incrociano allora sia \(u'v\) sia \(uv'\) sono archi di \(G\), entrambi stretti rispetto ad \(x\). 
\end{lemma}
\begin{proof}
	TODO\qed 
\end{proof}
\begin{definition}
	Diremo che \(x\in\text{STAB}(G)\) è \emph{localmente ottimo} se per ogni componente connessa \(K\) di \(G(x)\) valgono
	\[x_u=\frac{|A\cap K|}{|K|}\;\text{per ogni}\,u\in A\cap K\qquad\text{e}\qquad x_v=\frac{|B\cap K}{|K|}\;\text{per ogni}\,v\in B\cap K.\]
	Diremo che \(K\) è \emph{bilanciata} se per essa valgono le precedenti condizioni di ottimalità, \emph{sbilanciata} altrimenti. 
\end{definition}
\begin{definition}
	Sia \(x\in\text{STAB}^*(G)\). Diremo che una componente connessa \(K\) di \(G(x)\) è \emph{banale} se consiste di un unico vertice, \emph{non banale} altrimenti. Inoltre chiameremo \emph{libera} una componente che sia banale e sbilanciata. 
\end{definition}
\begin{definition}
	Sia \(x\in\text{STAB}^{*}(G)\). Diremo che una componente connessa \(L\) di \(G(x)\) è \emph{incastonata} in un'altra componente connessa \(K\) se esistono un vertice \(w\in L\) e due vertici \(u,u^{''}\in K\) tutti appartenenti ad un'unica catena e tali inoltre che \(u\le_{P}w\le_{P}u^{''}\). 
\end{definition}
\begin{lemma}
	\label{inlaylemma} Sia \(P\) un insieme parzialmente ordinato ricoperto da due catene disgiunte \(A\) e \(B\), sia inoltre \(G=\overline{G}(P)\). Dato \(x\in\text{STAB}^{*}(G)\) allora 
	\begin{enumerate}
		\item se in \(G(x)\) una componente connessa \(L\) è incastonata in \(K\) allora \(L\) è libera. 
		\item se \(K\) ed \(L\) sono componenti connesse non banali di \(G(x)\) allora vale \(K\le_{P}L\) oppure \(L\le_{P}K\). 
	\end{enumerate}
\end{lemma}
\begin{proof}
	TODO\qed 
\end{proof}
\begin{lemma}
	\label{touchinglemma} 
\end{lemma}
\begin{proof}
	TODO\qed 
\end{proof}
\begin{definition}
	Sia \(x\in\text{STAB}^{*}(G)\). Diciamo che una componente connessa \(K\) di \(G(x)\) è \emph{rossa} se si ha \(|A\cap K|\ge|B\cap K|\), altrimenti diciamo che \(K\) è \emph{blu}. 
\end{definition}
\begin{lemma}
	\label{consistentlemma} 
\end{lemma}
\begin{proof}
	TODO\qed 
\end{proof}
\begin{lemma}
	\label{hwanglinlemma} Siano \(X\) e \(Y\) due catene disgiunte. Supponiamo che \(|X|\ge|Y|\). Allora il numero di confronti richiesto dall'algoritmo di Hwang-Lin è maggiorato da \(|Y|\log(\frac{4|X|}{|Y|})\). 
\end{lemma}
\begin{proof}
	È noto che l'algoritmo di Hwang-Lin compie al più
	\[|Y|\left(1+\left\lfloor{\log{\frac{X}{Y}}}\right\rfloor\right)+\left\lfloor\frac{|X|}{2^{\left\lfloor\log{\frac{|X|}{|Y|}}\right\rfloor}}\right\rfloor-1\]
	confronti. Sia allora \(\xi\in\left[0,1\right)\) tale che
	\[\left\lfloor\log{\frac{|X|}{|Y|}}\right\rfloor=\log{\frac{|X|}{|Y|}}-\xi.\]
	È facile verificare che per \(\xi\in\left[0,1\right)\) valga la disuguaglianza
	\[1-\xi+2^{\xi}\le 2.\]
	Semplici passaggi algebrici danno
	\[\frac{|X|}{2^{\left\lfloor\log{\frac{|X|}{|Y|}}\right\rfloor}}=\frac{|X|}{2^{\log{\frac{|X|}{|Y|}}-\xi}}=\frac{|X|}{2^{\log{\frac{|X|}{|Y|}}}}\cdot 2^{\xi}=|Y|\cdot 2^{\xi}.\]
	Possiamo infine mettere insieme le precedenti due equazioni per ottenere 
	\begin{eqnarray}
		|Y|\left(1+\left\lfloor{\log{\frac{X}{Y}}}\right\rfloor\right)+\left\lfloor\frac{|X|}{2^{\left\lfloor\log{\frac{|X|}{|Y|}}\right\rfloor}}\right\rfloor-1&\le&|Y|\left(1-\xi+\log{\frac{|X|}{|Y|}}+2^{\xi}\right) \nonumber \\
		&\le& |Y|\left(\log{\frac{|X|}{|Y|}}+2\right) \nonumber \\
		&=& |Y|\left(\log{\frac{4|X|}{|Y|}}\right) \nonumber 
	\end{eqnarray}
	cioé la tesi.\qed 
\end{proof}
\begin{definition}
	Sia \(K\) una componente connessa di \(G(x)\). Se \(K\) è rossa chiamo \(A\cap K\) \emph{catena maggiore} e \(B\cap K\) \emph{catena minore}. Se \(K\) è blu il contrario. 
\end{definition}
\begin{definition}
	Sia \(K\) una componente connessa di \(G(x)\). Dico che \(K\) è \emph{buona} se ogni arco di \(G\) che possiede un estremo nella catena minore di \(K\) ha l'altro estremo nella catena maggiore oppure in una componente connessa di colore opposto. 
\end{definition}
\begin{lemma}
	\label{goodlemma} Sia \(x\in \text{STAB}(G)\) localmente ottimo. Se \(G(x)\) possiede almeno una componente rossa non banale allora una di esse è buona. 
\end{lemma}
\begin{proof}
	Sia \(K\) una componente connessa rossa non banale tale che \(\frac{|A\cap K|}{|K|}\) sia minimo. Vogliamo dimostrare che \(K\) è buona. Sia \(v\in B\cap K\) e sia \(w\) adiacente a \(v\) in \(G\) ma non in \(G(x)\). Per definizione l'arco di estremi \(v\) e \(w\) non è stretto, quindi \(x_v+x_w<1\). In particolare \(x_w<1\), quindi \(w\) appartiene ad una qualche componente connessa \(L\) non banale. Se per assurdo \(L\) fosse rossa per ipotesi \(\frac{|A\cap L|}{|L|}\ge\frac{|A\cap K|}{|K|}\), dunque per ottimalità di \(x\) avremo
	\[x_v+x_w=\frac{|B\cap K|}{|K|}+\frac{|A\cap L|}{|L|}\ge\frac{|B\cap K|}{|K|}+\frac{|A\cap K|}{|K|}\ge 1\]
	da cui dedurremmo che l'arco di estremi \(v\) e \(w\) è stretto, una contraddizione. Segue quindi che \(L\) è blu oppure non esiste \(w\) adiacente a \(v\) in \(G\) ma non in \(G(x)\), cioè la tesi.\qed 
\end{proof}
È immediato osservare che la precedente dimostrazione si applica, \emph{mutatis mutandis}, all'insieme delle componenti blu non banali. Pertanto in analoghe ipotesi esiste una componente blu che sia buona.

\begin{algorithm}
  \caption{``Merge''} \label{merge}
	\begin{algorithmic}
	  \STATE TODO
	\end{algorithmic}
\end{algorithm}

% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ %
\section{Merge sort} 
\begin{algorithm}
  \caption{``Merge sort''} \label{mergesort}
	\begin{algorithmic}
		\STATE trova una catena \(A\) di lunghezza massima in \(P\)
		\STATE applica l'algoritmo \ref{naivemerge} a \(P-A\), ottenendo una catena \(B\)
		\STATE applica l'algoritmo \ref{merge} all'ordine parziale corrente \(P'\)
		\RETURN la catena risultante
	\end{algorithmic}
\end{algorithm}